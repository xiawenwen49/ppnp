{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import logging\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "from ppnp.pytorch import PPNP, PPRGCN\n",
    "from ppnp.pytorch.training import train_model\n",
    "from ppnp.pytorch.earlystopping import stopping_args\n",
    "from ppnp.pytorch.propagation import PPRExact, PPRPowerIteration, DiffusionIteration, PrePPRIteration\n",
    "from ppnp.data.io import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "        format='%(asctime)s: %(message)s',\n",
    "        datefmt='%Y-%m-%d %H:%M:%S',\n",
    "        level=logging.INFO + 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch variant\n",
    "This is not the official code that should be used to reproduce the results from the paper (see `reproduce_results.ipynb` for this), but an adaptation of that code to PyTorch for better accessibility. This notebook reproduces the accuracy of the TensorFlow implementation, but has a longer computation time and varies in some details due to the change to PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Undirected, unweighted and connected SparseGraph with 88648 edges (no self-loops). Data: adj_matrix (19717x19717), attr_matrix (19717x500), labels (19717)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_name = 'pubmed' # cora_ml, citeseer, ms_academic, pubmed\n",
    "graph = load_dataset(graph_name)\n",
    "graph.standardize(select_lcc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "import sys\n",
    "sys.path.append('../gnn-untitled/')\n",
    "\n",
    "data_dir = Path('../gnn-untitled/pprie/data')\n",
    "graph_name = 'cora_ml_2c.SG'\n",
    "path_to_file = data_dir / graph_name\n",
    "\n",
    "with open(path_to_file, 'rb') as f:\n",
    "    new_graph = pickle.load(f)\n",
    "new_graph    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up data splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all we need to decide whether to use the test or validation set. Be mindful that we can only look at the test set exactly _once_ and then can't change any hyperparameters oder model details, no matter what. Everything else would cause overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the seeds for the dataset splits used in the paper for test/validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# test_seeds = [\n",
    "#         2144199730,  794209841, 2985733717, 2282690970, 1901557222,\n",
    "#         2009332812, 2266730407,  635625077, 3538425002,  960893189,\n",
    "#         497096336, 3940842554, 3594628340,  948012117, 3305901371,\n",
    "#         3644534211, 2297033685, 4092258879, 2590091101, 1694925034]\n",
    "# test_seeds = [2144199730, ]\n",
    "test_seeds = [\n",
    "        2144199730,  794209841, 2985733717, 2282690970, 1901557222,\n",
    "        ]\n",
    "val_seeds = [\n",
    "        2413340114, 3258769933, 1789234713, 2222151463, 2813247115,\n",
    "        1920426428, 4272044734, 2092442742, 841404887, 2188879532,\n",
    "        646784207, 1633698412, 2256863076,  374355442,  289680769,\n",
    "        4281139389, 4263036964,  900418539,  119332950, 1628837138]\n",
    "\n",
    "if test:\n",
    "    seeds = test_seeds\n",
    "else:\n",
    "    seeds = val_seeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can choose the remaining settings for the training/early stopping/validation(test) split. These are the ones chosen in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if graph_name == 'microsoft_academic':\n",
    "    nknown = 5000\n",
    "else:\n",
    "    nknown = 1500\n",
    "    \n",
    "idx_split_args = {'ntrain_per_class': 20, 'nstopping': 500, 'nknown': nknown}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up propagation\n",
    "\n",
    "Next we need to set up the proper pmropagation scheme. In the paper we've introduced the exact PPR propagation used in PPNP and the PPR power iteration propagation used in APPNP.\n",
    "\n",
    "We use the hyperparameters from the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 55s, sys: 1min 47s, total: 10min 42s\n",
      "Wall time: 10min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if graph_name == 'microsoft_academic':\n",
    "    alpha = 0.2\n",
    "else:\n",
    "    alpha = 0.1\n",
    "\n",
    "# prop_ppnp = PPRExact(graph.adj_matrix, alpha=alpha)\n",
    "# prop_appnp = PPRPowerIteration(graph.adj_matrix, alpha=alpha, niter=10)\n",
    "# prop_ppnp_d = DiffusionIteration(graph.adj_matrix, niter=10)\n",
    "prop_ppnp_pre = PrePPRIteration(graph.adj_matrix, alpha=alpha, niter=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose model hyperparameters\n",
    "\n",
    "Now we choose the hyperparameters. These are the ones used in the paper for all datasets.\n",
    "\n",
    "Note that we choose the propagation for APPNP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_args = {\n",
    "#     'hiddenunits': [64],\n",
    "#     'drop_prob': 0.5,\n",
    "#     'propagation': prop_appnp}\n",
    "\n",
    "model_args = {\n",
    "    'hiddenunits': [64],\n",
    "    'drop_prob': 0.5,\n",
    "    'propagation': prop_ppnp_pre}\n",
    "\n",
    "# model_args = {\n",
    "#     'adj_matrix': graph.adj_matrix,\n",
    "#     'hiddenunits': [64],\n",
    "#     'drop_prob': 0.5,\n",
    "#     'niter': 10,\n",
    "#     'alpha': alpha\n",
    "# }\n",
    "\n",
    "reg_lambda = 5e-3\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model\n",
    "\n",
    "First we set the remaining settings for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "niter_per_seed = 1\n",
    "save_result = False\n",
    "print_interval = 10\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use 20 different seeds for splitting and 5 iterations (different random initializations) per split, so we train 100 times altogether. This will take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-29 23:18:17: Iteration 1 of 5\n",
      "                     ----------------\n",
      "2020-05-29 23:18:17: PyTorch seed: 2562085068\n",
      "2020-05-29 23:19:51: Last epoch: 899, best epoch: 476 (93.757 sec)\n",
      "2020-05-29 23:19:51: Test accuracy: 80.4%\n",
      "2020-05-29 23:19:52: Iteration 2 of 5\n",
      "                     ----------------\n",
      "2020-05-29 23:19:52: PyTorch seed: 1077645736\n",
      "2020-05-29 23:21:26: Last epoch: 887, best epoch: 447 (94.480 sec)\n",
      "2020-05-29 23:21:26: Test accuracy: 75.4%\n",
      "2020-05-29 23:21:27: Iteration 3 of 5\n",
      "                     ----------------\n",
      "2020-05-29 23:21:27: PyTorch seed: 3317486348\n",
      "2020-05-29 23:22:25: Last epoch: 543, best epoch: 443 (58.001 sec)\n",
      "2020-05-29 23:22:25: Test accuracy: 78.7%\n",
      "2020-05-29 23:22:25: Iteration 4 of 5\n",
      "                     ----------------\n",
      "2020-05-29 23:22:25: PyTorch seed: 932514364\n",
      "2020-05-29 23:23:57: Last epoch: 869, best epoch: 769 (91.353 sec)\n",
      "2020-05-29 23:23:57: Test accuracy: 75.8%\n",
      "2020-05-29 23:23:57: Iteration 5 of 5\n",
      "                     ----------------\n",
      "2020-05-29 23:23:57: PyTorch seed: 2119378405\n",
      "2020-05-29 23:25:48: Last epoch: 1038, best epoch: 456 (110.916 sec)\n",
      "2020-05-29 23:25:49: Test accuracy: 79.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 14s, sys: 1min 32s, total: 7min 47s\n",
      "Wall time: 7min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = []\n",
    "niter_tot = niter_per_seed * len(seeds)\n",
    "i_tot = 0\n",
    "for seed in seeds:\n",
    "    idx_split_args['seed'] = seed\n",
    "    for _ in range(niter_per_seed):\n",
    "        i_tot += 1\n",
    "        logging_string = f\"Iteration {i_tot} of {niter_tot}\"\n",
    "        logging.log(22,\n",
    "                logging_string + \"\\n                     \"\n",
    "                + '-' * len(logging_string))\n",
    "        model, result = train_model(\n",
    "            graph_name, PPNP, graph, model_args, learning_rate, reg_lambda,\n",
    "            idx_split_args, stopping_args, test, device, None, print_interval)\n",
    "        results.append({})\n",
    "        results[-1]['stopping_accuracy'] = result['early_stopping']['accuracy']\n",
    "        results[-1]['valtest_accuracy'] = result['valtest']['accuracy']\n",
    "        results[-1]['runtime'] = result['runtime']\n",
    "        results[-1]['runtime_perepoch'] = result['runtime_perepoch']\n",
    "        results[-1]['split_seed'] = seed\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## forward computation time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 701 ms, sys: 74.6 ms, total: 776 ms\n",
      "Wall time: 105 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# from ppnp.preprocessing import normalize_attributes\n",
    "# from ppnp.pytorch.training import get_predictions\n",
    "# from ppnp.pytorch.utils import matrix_to_torch\n",
    "\n",
    "# labels_all = graph.labels\n",
    "# attr_mat_norm_np = normalize_attributes(graph.attr_matrix)\n",
    "# attr_mat_norm = matrix_to_torch(attr_mat_norm_np).to(device)\n",
    "\n",
    "# nfeatures = graph.attr_matrix.shape[1]\n",
    "# nclasses = max(labels_all) + 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_args = {\n",
    "#     'hiddenunits': [64],\n",
    "#     'drop_prob': 0.5,\n",
    "#     'propagation': prop_ppnp_pre}\n",
    "# model = PPNP(nfeatures, nclasses, **model_args).to(device)\n",
    "model.propagation = prop_ppnp_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.6 ms, sys: 128 µs, total: 24.7 ms\n",
      "Wall time: 23.7 ms\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%time res = get_predictions(model, attr_mat_norm, torch.arange(len(labels_all)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_args = {\n",
    "#     'hiddenunits': [64],\n",
    "#     'drop_prob': 0.5,\n",
    "#     'propagation': prop_appnp}\n",
    "# model = PPNP(nfeatures, nclasses, **model_args).to(device)\n",
    "model.propagation = prop_appnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.7 ms, sys: 0 ns, total: 35.7 ms\n",
      "Wall time: 34.9 ms\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%time res = get_predictions(model, attr_mat_norm, torch.arange(len(labels_all)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "To evaluate the data we use Pandas and Seaborn (for bootstrapping)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stopping_accuracy</th>\n",
       "      <th>valtest_accuracy</th>\n",
       "      <th>runtime</th>\n",
       "      <th>runtime_perepoch</th>\n",
       "      <th>split_seed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.810</td>\n",
       "      <td>0.803865</td>\n",
       "      <td>93.756767</td>\n",
       "      <td>0.104174</td>\n",
       "      <td>2144199730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.780</td>\n",
       "      <td>0.754131</td>\n",
       "      <td>94.480345</td>\n",
       "      <td>0.106397</td>\n",
       "      <td>794209841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.786</td>\n",
       "      <td>0.786793</td>\n",
       "      <td>58.000620</td>\n",
       "      <td>0.106619</td>\n",
       "      <td>2985733717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.754</td>\n",
       "      <td>0.757644</td>\n",
       "      <td>91.353143</td>\n",
       "      <td>0.105004</td>\n",
       "      <td>2282690970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.794</td>\n",
       "      <td>0.795301</td>\n",
       "      <td>110.916467</td>\n",
       "      <td>0.106753</td>\n",
       "      <td>1901557222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stopping_accuracy  valtest_accuracy     runtime  runtime_perepoch  \\\n",
       "0              0.810          0.803865   93.756767          0.104174   \n",
       "1              0.780          0.754131   94.480345          0.106397   \n",
       "2              0.786          0.786793   58.000620          0.106619   \n",
       "3              0.754          0.757644   91.353143          0.105004   \n",
       "4              0.794          0.795301  110.916467          0.106753   \n",
       "\n",
       "   split_seed  \n",
       "0  2144199730  \n",
       "1   794209841  \n",
       "2  2985733717  \n",
       "3  2282690970  \n",
       "4  1901557222  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.DataFrame(results)\n",
    "result_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard deviation doesn't really say much about the uncertainty of our results and the standard error of the mean (SEM) assumes a normal distribution. So the best way to get a valid estimate for our results' uncertainty is via bootstrapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_uncertainty(values: np.ndarray, n_boot: int = 1000, ci: int = 95) -> dict:\n",
    "    stats = {}\n",
    "    stats['mean'] = values.mean()\n",
    "    boots_series = sns.algorithms.bootstrap(values, func=np.mean, n_boot=n_boot)\n",
    "    stats['CI'] = sns.utils.ci(boots_series, ci)\n",
    "    stats['uncertainty'] = np.max(np.abs(stats['CI'] - stats['mean']))\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopping_acc = calc_uncertainty(result_df['stopping_accuracy'])\n",
    "valtest_acc = calc_uncertainty(result_df['valtest_accuracy'])\n",
    "runtime = calc_uncertainty(result_df['runtime'])\n",
    "runtime_perepoch = calc_uncertainty(result_df['runtime_perepoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APPNP\n",
      "Early stopping: Accuracy: 78.48 ± 1.64%\n",
      "Test: Accuracy: 77.95 ± 1.75%\n",
      "Runtime: 89.701 ± 17.734 sec, per epoch: 105.79 ± 0.96ms\n"
     ]
    }
   ],
   "source": [
    "print(\"APPNP\\n\"\n",
    "      \"Early stopping: Accuracy: {:.2f} ± {:.2f}%\\n\"\n",
    "      \"{}: Accuracy: {:.2f} ± {:.2f}%\\n\"\n",
    "      \"Runtime: {:.3f} ± {:.3f} sec, per epoch: {:.2f} ± {:.2f}ms\"\n",
    "      .format(\n",
    "          stopping_acc['mean'] * 100,\n",
    "          stopping_acc['uncertainty'] * 100,\n",
    "          'Test' if test else 'Validation',\n",
    "          valtest_acc['mean'] * 100,\n",
    "          valtest_acc['uncertainty'] * 100,\n",
    "          runtime['mean'],\n",
    "          runtime['uncertainty'],\n",
    "          runtime_perepoch['mean'] * 1e3,\n",
    "          runtime_perepoch['uncertainty'] * 1e3,\n",
    "      ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "original:\n",
    "APPNP\n",
    "Early stopping: Accuracy: 80.40 ± 0.00%\n",
    "Test: Accuracy: 82.90 ± 0.00%\n",
    "Runtime: 62.598 ± 0.000 sec, per epoch: 41.29 ± 0.00ms\n",
    "\n",
    "re-run:\n",
    "APPNP\n",
    "Early stopping: Accuracy: 81.23 ± 0.42%\n",
    "Test: Accuracy: 83.60 ± 0.32%\n",
    "Runtime: 71.608 ± 2.747 sec, per epoch: 42.81 ± 0.37ms\n",
    "\n",
    "ppnp_d:\n",
    "A is symmatric, niter=6\n",
    "APPNP\n",
    "Early stopping: Accuracy: 77.94 ± 0.59%\n",
    "Test: Accuracy: 79.70 ± 0.45%\n",
    "Runtime: 3.912 ± 0.358 sec, per epoch: 20.55 ± 0.15ms\n",
    "\n",
    "ppnp_d:\n",
    "A is symmatric, niter=10\n",
    "APPNP\n",
    "Early stopping: Accuracy: 78.37 ± 0.62%\n",
    "Test: Accuracy: 80.38 ± 0.50%\n",
    "Runtime: 4.173 ± 0.235 sec, per epoch: 21.68 ± 0.12ms\n",
    "\n",
    "ppnp_pre:\n",
    "pre-compute PPR matrix (iterative), niter=10\n",
    "APPNP\n",
    "Early stopping: Accuracy: 81.34 ± 0.41%\n",
    "Test: Accuracy: 83.74 ± 0.30%\n",
    "Runtime: 32.504 ± 1.218 sec, per epoch: 19.06 ± 0.11ms\n",
    "\n",
    "ppnp_pre:\n",
    "pre-compute PPR matrix (iterative), niter=20\n",
    "APPNP\n",
    "Early stopping: Accuracy: 81.34 ± 0.39%\n",
    "Test: Accuracy: 83.74 ± 0.33%\n",
    "Runtime: 32.048 ± 1.240 sec, per epoch: 18.94 ± 0.10ms\n",
    "\n",
    "PPRGCN:\n",
    "APPNP\n",
    "Early stopping: Accuracy: 80.95 ± 0.46%\n",
    "Test: Accuracy: 83.38 ± 0.32%\n",
    "Runtime: 25.545 ± 1.067 sec, per epoch: 18.63 ± 0.07ms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
