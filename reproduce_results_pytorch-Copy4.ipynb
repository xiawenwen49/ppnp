{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import logging\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "from ppnp.pytorch import PPNP, PPRGCN\n",
    "from ppnp.pytorch.training import train_model\n",
    "from ppnp.pytorch.earlystopping import stopping_args\n",
    "from ppnp.pytorch.propagation import PPRExact, PPRPowerIteration, DiffusionIteration, PrePPRIteration\n",
    "from ppnp.data.io import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "        format='%(asctime)s: %(message)s',\n",
    "        datefmt='%Y-%m-%d %H:%M:%S',\n",
    "        level=logging.INFO + 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch variant\n",
    "This is not the official code that should be used to reproduce the results from the paper (see `reproduce_results.ipynb` for this), but an adaptation of that code to PyTorch for better accessibility. This notebook reproduces the accuracy of the TensorFlow implementation, but has a longer computation time and varies in some details due to the change to PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Undirected, unweighted and connected SparseGraph with 88648 edges (no self-loops). Data: adj_matrix (19717x19717), attr_matrix (19717x500), labels (19717)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_name = 'pubmed' # cora_ml, citeseer, ms_academic, pubmed\n",
    "graph = load_dataset(graph_name)\n",
    "graph.standardize(select_lcc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "import sys\n",
    "sys.path.append('../gnn-untitled/')\n",
    "\n",
    "data_dir = Path('../gnn-untitled/pprie/data')\n",
    "graph_name = 'cora_ml_2c.SG'\n",
    "path_to_file = data_dir / graph_name\n",
    "\n",
    "with open(path_to_file, 'rb') as f:\n",
    "    new_graph = pickle.load(f)\n",
    "new_graph    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up data splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all we need to decide whether to use the test or validation set. Be mindful that we can only look at the test set exactly _once_ and then can't change any hyperparameters oder model details, no matter what. Everything else would cause overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the seeds for the dataset splits used in the paper for test/validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_seeds = [\n",
    "        2144199730,  794209841, 2985733717, 2282690970, 1901557222,\n",
    "        2009332812, 2266730407,  635625077, 3538425002,  960893189,\n",
    "        497096336, 3940842554, 3594628340,  948012117, 3305901371,\n",
    "        3644534211, 2297033685, 4092258879, 2590091101, 1694925034]\n",
    "# test_seeds = [2144199730, ]\n",
    "\n",
    "val_seeds = [\n",
    "        2413340114, 3258769933, 1789234713, 2222151463, 2813247115,\n",
    "        1920426428, 4272044734, 2092442742, 841404887, 2188879532,\n",
    "        646784207, 1633698412, 2256863076,  374355442,  289680769,\n",
    "        4281139389, 4263036964,  900418539,  119332950, 1628837138]\n",
    "\n",
    "if test:\n",
    "    seeds = test_seeds\n",
    "else:\n",
    "    seeds = val_seeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can choose the remaining settings for the training/early stopping/validation(test) split. These are the ones chosen in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if graph_name == 'microsoft_academic':\n",
    "    nknown = 5000\n",
    "else:\n",
    "    nknown = 1500\n",
    "    \n",
    "idx_split_args = {'ntrain_per_class': 20, 'nstopping': 500, 'nknown': nknown}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up propagation\n",
    "\n",
    "Next we need to set up the proper pmropagation scheme. In the paper we've introduced the exact PPR propagation used in PPNP and the PPR power iteration propagation used in APPNP.\n",
    "\n",
    "We use the hyperparameters from the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20min 44s, sys: 2min 52s, total: 23min 36s\n",
      "Wall time: 23min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if graph_name == 'microsoft_academic':\n",
    "    alpha = 0.2\n",
    "else:\n",
    "    alpha = 0.1\n",
    "\n",
    "# prop_ppnp = PPRExact(graph.adj_matrix, alpha=alpha)\n",
    "# prop_appnp = PPRPowerIteration(graph.adj_matrix, alpha=alpha, niter=10)\n",
    "# prop_ppnp_d = DiffusionIteration(graph.adj_matrix, niter=10)\n",
    "prop_ppnp_pre = PrePPRIteration(graph.adj_matrix, alpha=alpha, niter=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose model hyperparameters\n",
    "\n",
    "Now we choose the hyperparameters. These are the ones used in the paper for all datasets.\n",
    "\n",
    "Note that we choose the propagation for APPNP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_args = {\n",
    "#     'hiddenunits': [64],\n",
    "#     'drop_prob': 0.5,\n",
    "#     'propagation': prop_appnp}\n",
    "\n",
    "model_args = {\n",
    "    'hiddenunits': [64],\n",
    "    'drop_prob': 0.5,\n",
    "    'propagation': prop_ppnp_pre}\n",
    "\n",
    "# model_args = {\n",
    "#     'adj_matrix': graph.adj_matrix,\n",
    "#     'hiddenunits': [64],\n",
    "#     'drop_prob': 0.5,\n",
    "#     'niter': 10,\n",
    "#     'alpha': alpha\n",
    "# }\n",
    "\n",
    "reg_lambda = 5e-3\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model\n",
    "\n",
    "First we set the remaining settings for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "niter_per_seed = 1\n",
    "save_result = False\n",
    "print_interval = 10\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use 20 different seeds for splitting and 5 iterations (different random initializations) per split, so we train 100 times altogether. This will take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-29 21:56:38: Iteration 1 of 20\n",
      "                     -----------------\n",
      "2020-05-29 21:56:38: PyTorch seed: 2663962916\n",
      "2020-05-29 21:58:32: Last epoch: 1098, best epoch: 928 (114.493 sec)\n",
      "2020-05-29 21:58:33: Test accuracy: 79.9%\n",
      "2020-05-29 21:58:33: Iteration 2 of 20\n",
      "                     -----------------\n",
      "2020-05-29 21:58:33: PyTorch seed: 1371457318\n",
      "2020-05-29 22:00:02: Last epoch: 835, best epoch: 189 (89.220 sec)\n",
      "2020-05-29 22:00:02: Test accuracy: 74.2%\n",
      "2020-05-29 22:00:02: Iteration 3 of 20\n",
      "                     -----------------\n",
      "2020-05-29 22:00:03: PyTorch seed: 3151321874\n",
      "2020-05-29 22:01:26: Last epoch: 799, best epoch: 600 (83.708 sec)\n",
      "2020-05-29 22:01:27: Test accuracy: 78.5%\n",
      "2020-05-29 22:01:27: Iteration 4 of 20\n",
      "                     -----------------\n",
      "2020-05-29 22:01:27: PyTorch seed: 1749326150\n",
      "2020-05-29 22:03:02: Last epoch: 884, best epoch: 374 (94.610 sec)\n",
      "2020-05-29 22:03:02: Test accuracy: 77.4%\n",
      "2020-05-29 22:03:02: Iteration 5 of 20\n",
      "                     -----------------\n",
      "2020-05-29 22:03:02: PyTorch seed: 2318918249\n",
      "2020-05-29 22:04:34: Last epoch: 881, best epoch: 531 (92.309 sec)\n",
      "2020-05-29 22:04:35: Test accuracy: 79.9%\n",
      "2020-05-29 22:04:35: Iteration 6 of 20\n",
      "                     -----------------\n",
      "2020-05-29 22:04:35: PyTorch seed: 2249178992\n",
      "2020-05-29 22:06:27: Last epoch: 1050, best epoch: 487 (111.980 sec)\n",
      "2020-05-29 22:06:27: Test accuracy: 80.2%\n",
      "2020-05-29 22:06:27: Iteration 7 of 20\n",
      "                     -----------------\n",
      "2020-05-29 22:06:27: PyTorch seed: 504687203\n",
      "2020-05-29 22:08:32: Last epoch: 1181, best epoch: 759 (124.673 sec)\n",
      "2020-05-29 22:08:32: Test accuracy: 80.4%\n",
      "2020-05-29 22:08:33: Iteration 8 of 20\n",
      "                     -----------------\n",
      "2020-05-29 22:08:33: PyTorch seed: 4032983673\n",
      "2020-05-29 22:10:03: Last epoch: 850, best epoch: 527 (89.795 sec)\n",
      "2020-05-29 22:10:03: Test accuracy: 79.6%\n",
      "2020-05-29 22:10:03: Iteration 9 of 20\n",
      "                     -----------------\n",
      "2020-05-29 22:10:03: PyTorch seed: 696631971\n",
      "2020-05-29 22:11:38: Last epoch: 893, best epoch: 764 (94.586 sec)\n",
      "2020-05-29 22:11:38: Test accuracy: 81.7%\n",
      "2020-05-29 22:11:38: Iteration 10 of 20\n",
      "                     ------------------\n",
      "2020-05-29 22:11:38: PyTorch seed: 131246703\n",
      "2020-05-29 22:13:48: Last epoch: 1239, best epoch: 1104 (129.810 sec)\n",
      "2020-05-29 22:13:48: Test accuracy: 79.7%\n",
      "2020-05-29 22:13:49: Iteration 11 of 20\n",
      "                     ------------------\n",
      "2020-05-29 22:13:49: PyTorch seed: 86613612\n",
      "2020-05-29 22:15:24: Last epoch: 913, best epoch: 717 (95.587 sec)\n",
      "2020-05-29 22:15:25: Test accuracy: 80.7%\n",
      "2020-05-29 22:15:25: Iteration 12 of 20\n",
      "                     ------------------\n",
      "2020-05-29 22:15:25: PyTorch seed: 571074363\n",
      "2020-05-29 22:16:49: Last epoch: 805, best epoch: 640 (84.350 sec)\n",
      "2020-05-29 22:16:50: Test accuracy: 80.2%\n",
      "2020-05-29 22:16:50: Iteration 13 of 20\n",
      "                     ------------------\n",
      "2020-05-29 22:16:50: PyTorch seed: 1164924724\n",
      "2020-05-29 22:18:16: Last epoch: 812, best epoch: 562 (85.900 sec)\n",
      "2020-05-29 22:18:16: Test accuracy: 78.7%\n",
      "2020-05-29 22:18:16: Iteration 14 of 20\n",
      "                     ------------------\n",
      "2020-05-29 22:18:16: PyTorch seed: 4103790760\n",
      "2020-05-29 22:19:56: Last epoch: 936, best epoch: 545 (99.847 sec)\n",
      "2020-05-29 22:19:57: Test accuracy: 77.4%\n",
      "2020-05-29 22:19:57: Iteration 15 of 20\n",
      "                     ------------------\n",
      "2020-05-29 22:19:57: PyTorch seed: 4003619469\n",
      "2020-05-29 22:21:14: Last epoch: 722, best epoch: 478 (77.265 sec)\n",
      "2020-05-29 22:21:14: Test accuracy: 75.9%\n",
      "2020-05-29 22:21:14: Iteration 16 of 20\n",
      "                     ------------------\n",
      "2020-05-29 22:21:15: PyTorch seed: 146042797\n",
      "2020-05-29 22:22:44: Last epoch: 834, best epoch: 590 (89.510 sec)\n",
      "2020-05-29 22:22:44: Test accuracy: 79.3%\n",
      "2020-05-29 22:22:45: Iteration 17 of 20\n",
      "                     ------------------\n",
      "2020-05-29 22:22:45: PyTorch seed: 822114978\n",
      "2020-05-29 22:24:26: Last epoch: 949, best epoch: 849 (101.569 sec)\n",
      "2020-05-29 22:24:27: Test accuracy: 78.2%\n",
      "2020-05-29 22:24:27: Iteration 18 of 20\n",
      "                     ------------------\n",
      "2020-05-29 22:24:27: PyTorch seed: 3500460101\n",
      "2020-05-29 22:25:40: Last epoch: 679, best epoch: 393 (72.842 sec)\n",
      "2020-05-29 22:25:40: Test accuracy: 79.5%\n",
      "2020-05-29 22:25:40: Iteration 19 of 20\n",
      "                     ------------------\n",
      "2020-05-29 22:25:40: PyTorch seed: 1361909502\n",
      "2020-05-29 22:26:49: Last epoch: 652, best epoch: 552 (68.385 sec)\n",
      "2020-05-29 22:26:49: Test accuracy: 74.3%\n",
      "2020-05-29 22:26:49: Iteration 20 of 20\n",
      "                     ------------------\n",
      "2020-05-29 22:26:49: PyTorch seed: 4037030730\n",
      "2020-05-29 22:28:06: Last epoch: 718, best epoch: 618 (76.573 sec)\n",
      "2020-05-29 22:28:06: Test accuracy: 76.3%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25min 53s, sys: 6min 31s, total: 32min 24s\n",
      "Wall time: 31min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = []\n",
    "niter_tot = niter_per_seed * len(seeds)\n",
    "i_tot = 0\n",
    "for seed in seeds:\n",
    "    idx_split_args['seed'] = seed\n",
    "    for _ in range(niter_per_seed):\n",
    "        i_tot += 1\n",
    "        logging_string = f\"Iteration {i_tot} of {niter_tot}\"\n",
    "        logging.log(22,\n",
    "                logging_string + \"\\n                     \"\n",
    "                + '-' * len(logging_string))\n",
    "        model, result = train_model(\n",
    "            graph_name, PPNP, graph, model_args, learning_rate, reg_lambda,\n",
    "            idx_split_args, stopping_args, test, device, None, print_interval)\n",
    "        results.append({})\n",
    "        results[-1]['stopping_accuracy'] = result['early_stopping']['accuracy']\n",
    "        results[-1]['valtest_accuracy'] = result['valtest']['accuracy']\n",
    "        results[-1]['runtime'] = result['runtime']\n",
    "        results[-1]['runtime_perepoch'] = result['runtime_perepoch']\n",
    "        results[-1]['split_seed'] = seed\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## forward computation time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 701 ms, sys: 74.6 ms, total: 776 ms\n",
      "Wall time: 105 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# from ppnp.preprocessing import normalize_attributes\n",
    "# from ppnp.pytorch.training import get_predictions\n",
    "# from ppnp.pytorch.utils import matrix_to_torch\n",
    "\n",
    "# labels_all = graph.labels\n",
    "# attr_mat_norm_np = normalize_attributes(graph.attr_matrix)\n",
    "# attr_mat_norm = matrix_to_torch(attr_mat_norm_np).to(device)\n",
    "\n",
    "# nfeatures = graph.attr_matrix.shape[1]\n",
    "# nclasses = max(labels_all) + 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_args = {\n",
    "#     'hiddenunits': [64],\n",
    "#     'drop_prob': 0.5,\n",
    "#     'propagation': prop_ppnp_pre}\n",
    "# model = PPNP(nfeatures, nclasses, **model_args).to(device)\n",
    "model.propagation = prop_ppnp_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.6 ms, sys: 128 µs, total: 24.7 ms\n",
      "Wall time: 23.7 ms\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%time res = get_predictions(model, attr_mat_norm, torch.arange(len(labels_all)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_args = {\n",
    "#     'hiddenunits': [64],\n",
    "#     'drop_prob': 0.5,\n",
    "#     'propagation': prop_appnp}\n",
    "# model = PPNP(nfeatures, nclasses, **model_args).to(device)\n",
    "model.propagation = prop_appnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.7 ms, sys: 0 ns, total: 35.7 ms\n",
      "Wall time: 34.9 ms\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%time res = get_predictions(model, attr_mat_norm, torch.arange(len(labels_all)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "To evaluate the data we use Pandas and Seaborn (for bootstrapping)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stopping_accuracy</th>\n",
       "      <th>valtest_accuracy</th>\n",
       "      <th>runtime</th>\n",
       "      <th>runtime_perepoch</th>\n",
       "      <th>split_seed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.796</td>\n",
       "      <td>0.799034</td>\n",
       "      <td>114.492849</td>\n",
       "      <td>0.104179</td>\n",
       "      <td>2144199730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.780</td>\n",
       "      <td>0.742164</td>\n",
       "      <td>89.220110</td>\n",
       "      <td>0.106723</td>\n",
       "      <td>794209841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.782</td>\n",
       "      <td>0.785091</td>\n",
       "      <td>83.708076</td>\n",
       "      <td>0.104635</td>\n",
       "      <td>2985733717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.762</td>\n",
       "      <td>0.774387</td>\n",
       "      <td>94.609716</td>\n",
       "      <td>0.106904</td>\n",
       "      <td>2282690970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.799144</td>\n",
       "      <td>92.309059</td>\n",
       "      <td>0.104659</td>\n",
       "      <td>1901557222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.810</td>\n",
       "      <td>0.801833</td>\n",
       "      <td>111.979774</td>\n",
       "      <td>0.106546</td>\n",
       "      <td>2009332812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.820</td>\n",
       "      <td>0.804359</td>\n",
       "      <td>124.673407</td>\n",
       "      <td>0.105477</td>\n",
       "      <td>2266730407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.796344</td>\n",
       "      <td>89.794794</td>\n",
       "      <td>0.105517</td>\n",
       "      <td>635625077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.828</td>\n",
       "      <td>0.817204</td>\n",
       "      <td>94.586060</td>\n",
       "      <td>0.105801</td>\n",
       "      <td>3538425002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.796948</td>\n",
       "      <td>129.809917</td>\n",
       "      <td>0.104685</td>\n",
       "      <td>960893189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.764</td>\n",
       "      <td>0.807213</td>\n",
       "      <td>95.587416</td>\n",
       "      <td>0.104581</td>\n",
       "      <td>497096336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.801833</td>\n",
       "      <td>84.350431</td>\n",
       "      <td>0.104653</td>\n",
       "      <td>3940842554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.792</td>\n",
       "      <td>0.786518</td>\n",
       "      <td>85.899752</td>\n",
       "      <td>0.105658</td>\n",
       "      <td>3594628340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.792</td>\n",
       "      <td>0.773618</td>\n",
       "      <td>99.846877</td>\n",
       "      <td>0.106560</td>\n",
       "      <td>948012117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.772</td>\n",
       "      <td>0.759016</td>\n",
       "      <td>77.264973</td>\n",
       "      <td>0.106867</td>\n",
       "      <td>3305901371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.790</td>\n",
       "      <td>0.792831</td>\n",
       "      <td>89.509720</td>\n",
       "      <td>0.107197</td>\n",
       "      <td>3644534211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.781797</td>\n",
       "      <td>101.568871</td>\n",
       "      <td>0.106915</td>\n",
       "      <td>2297033685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.795301</td>\n",
       "      <td>72.841906</td>\n",
       "      <td>0.107120</td>\n",
       "      <td>4092258879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.732</td>\n",
       "      <td>0.743207</td>\n",
       "      <td>68.384634</td>\n",
       "      <td>0.104724</td>\n",
       "      <td>2590091101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.736</td>\n",
       "      <td>0.762584</td>\n",
       "      <td>76.573181</td>\n",
       "      <td>0.106500</td>\n",
       "      <td>1694925034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    stopping_accuracy  valtest_accuracy     runtime  runtime_perepoch  \\\n",
       "0               0.796          0.799034  114.492849          0.104179   \n",
       "1               0.780          0.742164   89.220110          0.106723   \n",
       "2               0.782          0.785091   83.708076          0.104635   \n",
       "3               0.762          0.774387   94.609716          0.106904   \n",
       "4               0.798          0.799144   92.309059          0.104659   \n",
       "5               0.810          0.801833  111.979774          0.106546   \n",
       "6               0.820          0.804359  124.673407          0.105477   \n",
       "7               0.798          0.796344   89.794794          0.105517   \n",
       "8               0.828          0.817204   94.586060          0.105801   \n",
       "9               0.800          0.796948  129.809917          0.104685   \n",
       "10              0.764          0.807213   95.587416          0.104581   \n",
       "11              0.804          0.801833   84.350431          0.104653   \n",
       "12              0.792          0.786518   85.899752          0.105658   \n",
       "13              0.792          0.773618   99.846877          0.106560   \n",
       "14              0.772          0.759016   77.264973          0.106867   \n",
       "15              0.790          0.792831   89.509720          0.107197   \n",
       "16              0.800          0.781797  101.568871          0.106915   \n",
       "17              0.808          0.795301   72.841906          0.107120   \n",
       "18              0.732          0.743207   68.384634          0.104724   \n",
       "19              0.736          0.762584   76.573181          0.106500   \n",
       "\n",
       "    split_seed  \n",
       "0   2144199730  \n",
       "1    794209841  \n",
       "2   2985733717  \n",
       "3   2282690970  \n",
       "4   1901557222  \n",
       "5   2009332812  \n",
       "6   2266730407  \n",
       "7    635625077  \n",
       "8   3538425002  \n",
       "9    960893189  \n",
       "10   497096336  \n",
       "11  3940842554  \n",
       "12  3594628340  \n",
       "13   948012117  \n",
       "14  3305901371  \n",
       "15  3644534211  \n",
       "16  2297033685  \n",
       "17  4092258879  \n",
       "18  2590091101  \n",
       "19  1694925034  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.DataFrame(results)\n",
    "result_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard deviation doesn't really say much about the uncertainty of our results and the standard error of the mean (SEM) assumes a normal distribution. So the best way to get a valid estimate for our results' uncertainty is via bootstrapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_uncertainty(values: np.ndarray, n_boot: int = 1000, ci: int = 95) -> dict:\n",
    "    stats = {}\n",
    "    stats['mean'] = values.mean()\n",
    "    boots_series = sns.algorithms.bootstrap(values, func=np.mean, n_boot=n_boot)\n",
    "    stats['CI'] = sns.utils.ci(boots_series, ci)\n",
    "    stats['uncertainty'] = np.max(np.abs(stats['CI'] - stats['mean']))\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopping_acc = calc_uncertainty(result_df['stopping_accuracy'])\n",
    "valtest_acc = calc_uncertainty(result_df['valtest_accuracy'])\n",
    "runtime = calc_uncertainty(result_df['runtime'])\n",
    "runtime_perepoch = calc_uncertainty(result_df['runtime_perepoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APPNP\n",
      "Early stopping: Accuracy: 78.82 ± 1.10%\n",
      "Test: Accuracy: 78.60 ± 0.94%\n",
      "Runtime: 93.851 ± 7.397 sec, per epoch: 105.80 ± 0.41ms\n"
     ]
    }
   ],
   "source": [
    "print(\"APPNP\\n\"\n",
    "      \"Early stopping: Accuracy: {:.2f} ± {:.2f}%\\n\"\n",
    "      \"{}: Accuracy: {:.2f} ± {:.2f}%\\n\"\n",
    "      \"Runtime: {:.3f} ± {:.3f} sec, per epoch: {:.2f} ± {:.2f}ms\"\n",
    "      .format(\n",
    "          stopping_acc['mean'] * 100,\n",
    "          stopping_acc['uncertainty'] * 100,\n",
    "          'Test' if test else 'Validation',\n",
    "          valtest_acc['mean'] * 100,\n",
    "          valtest_acc['uncertainty'] * 100,\n",
    "          runtime['mean'],\n",
    "          runtime['uncertainty'],\n",
    "          runtime_perepoch['mean'] * 1e3,\n",
    "          runtime_perepoch['uncertainty'] * 1e3,\n",
    "      ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "original:\n",
    "APPNP\n",
    "Early stopping: Accuracy: 80.40 ± 0.00%\n",
    "Test: Accuracy: 82.90 ± 0.00%\n",
    "Runtime: 62.598 ± 0.000 sec, per epoch: 41.29 ± 0.00ms\n",
    "\n",
    "re-run:\n",
    "APPNP\n",
    "Early stopping: Accuracy: 81.23 ± 0.42%\n",
    "Test: Accuracy: 83.60 ± 0.32%\n",
    "Runtime: 71.608 ± 2.747 sec, per epoch: 42.81 ± 0.37ms\n",
    "\n",
    "ppnp_d:\n",
    "A is symmatric, niter=6\n",
    "APPNP\n",
    "Early stopping: Accuracy: 77.94 ± 0.59%\n",
    "Test: Accuracy: 79.70 ± 0.45%\n",
    "Runtime: 3.912 ± 0.358 sec, per epoch: 20.55 ± 0.15ms\n",
    "\n",
    "ppnp_d:\n",
    "A is symmatric, niter=10\n",
    "APPNP\n",
    "Early stopping: Accuracy: 78.37 ± 0.62%\n",
    "Test: Accuracy: 80.38 ± 0.50%\n",
    "Runtime: 4.173 ± 0.235 sec, per epoch: 21.68 ± 0.12ms\n",
    "\n",
    "ppnp_pre:\n",
    "pre-compute PPR matrix (iterative), niter=10\n",
    "APPNP\n",
    "Early stopping: Accuracy: 81.34 ± 0.41%\n",
    "Test: Accuracy: 83.74 ± 0.30%\n",
    "Runtime: 32.504 ± 1.218 sec, per epoch: 19.06 ± 0.11ms\n",
    "\n",
    "ppnp_pre:\n",
    "pre-compute PPR matrix (iterative), niter=20\n",
    "APPNP\n",
    "Early stopping: Accuracy: 81.34 ± 0.39%\n",
    "Test: Accuracy: 83.74 ± 0.33%\n",
    "Runtime: 32.048 ± 1.240 sec, per epoch: 18.94 ± 0.10ms\n",
    "\n",
    "PPRGCN:\n",
    "APPNP\n",
    "Early stopping: Accuracy: 80.95 ± 0.46%\n",
    "Test: Accuracy: 83.38 ± 0.32%\n",
    "Runtime: 25.545 ± 1.067 sec, per epoch: 18.63 ± 0.07ms\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
