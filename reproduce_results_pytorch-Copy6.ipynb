{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import logging\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "from ppnp.pytorch import PPNP, PPRGCN\n",
    "from ppnp.pytorch.training import train_model\n",
    "from ppnp.pytorch.earlystopping import stopping_args\n",
    "from ppnp.pytorch.propagation import PPRExact, PPRPowerIteration, DiffusionIteration, PrePPRIteration\n",
    "from ppnp.data.io import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "        format='%(asctime)s: %(message)s',\n",
    "        datefmt='%Y-%m-%d %H:%M:%S',\n",
    "        level=logging.INFO + 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch variant\n",
    "This is not the official code that should be used to reproduce the results from the paper (see `reproduce_results.ipynb` for this), but an adaptation of that code to PyTorch for better accessibility. This notebook reproduces the accuracy of the TensorFlow implementation, but has a longer computation time and varies in some details due to the change to PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Undirected, unweighted and connected SparseGraph with 88648 edges (no self-loops). Data: adj_matrix (19717x19717), attr_matrix (19717x500), labels (19717)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_name = 'pubmed' # cora_ml, citeseer, ms_academic, pubmed\n",
    "graph = load_dataset(graph_name)\n",
    "graph.standardize(select_lcc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "import sys\n",
    "sys.path.append('../gnn-untitled/')\n",
    "\n",
    "data_dir = Path('../gnn-untitled/pprie/data')\n",
    "graph_name = 'cora_ml_2c.SG'\n",
    "path_to_file = data_dir / graph_name\n",
    "\n",
    "with open(path_to_file, 'rb') as f:\n",
    "    new_graph = pickle.load(f)\n",
    "new_graph    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up data splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all we need to decide whether to use the test or validation set. Be mindful that we can only look at the test set exactly _once_ and then can't change any hyperparameters oder model details, no matter what. Everything else would cause overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the seeds for the dataset splits used in the paper for test/validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_seeds = [\n",
    "        2144199730,  794209841, 2985733717, 2282690970, 1901557222,\n",
    "        2009332812, 2266730407,  635625077, 3538425002,  960893189,\n",
    "        497096336, 3940842554, 3594628340,  948012117, 3305901371,\n",
    "        3644534211, 2297033685, 4092258879, 2590091101, 1694925034]\n",
    "# test_seeds = [2144199730, ]\n",
    "\n",
    "val_seeds = [\n",
    "        2413340114, 3258769933, 1789234713, 2222151463, 2813247115,\n",
    "        1920426428, 4272044734, 2092442742, 841404887, 2188879532,\n",
    "        646784207, 1633698412, 2256863076,  374355442,  289680769,\n",
    "        4281139389, 4263036964,  900418539,  119332950, 1628837138]\n",
    "\n",
    "if test:\n",
    "    seeds = test_seeds\n",
    "else:\n",
    "    seeds = val_seeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can choose the remaining settings for the training/early stopping/validation(test) split. These are the ones chosen in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if graph_name == 'microsoft_academic':\n",
    "    nknown = 5000\n",
    "else:\n",
    "    nknown = 1500\n",
    "    \n",
    "idx_split_args = {'ntrain_per_class': 20, 'nstopping': 500, 'nknown': nknown}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up propagation\n",
    "\n",
    "Next we need to set up the proper pmropagation scheme. In the paper we've introduced the exact PPR propagation used in PPNP and the PPR power iteration propagation used in APPNP.\n",
    "\n",
    "We use the hyperparameters from the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38.6 ms, sys: 5.57 ms, total: 44.1 ms\n",
      "Wall time: 14.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if graph_name == 'microsoft_academic':\n",
    "    alpha = 0.2\n",
    "else:\n",
    "    alpha = 0.1\n",
    "\n",
    "# prop_ppnp = PPRExact(graph.adj_matrix, alpha=alpha)\n",
    "prop_appnp = PPRPowerIteration(graph.adj_matrix, alpha=alpha, niter=20)\n",
    "# prop_ppnp_d = DiffusionIteration(graph.adj_matrix, niter=10)\n",
    "# prop_ppnp_pre = PrePPRIteration(graph.adj_matrix, alpha=alpha, niter=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose model hyperparameters\n",
    "\n",
    "Now we choose the hyperparameters. These are the ones used in the paper for all datasets.\n",
    "\n",
    "Note that we choose the propagation for APPNP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = {\n",
    "    'hiddenunits': [64],\n",
    "    'drop_prob': 0.5,\n",
    "    'propagation': prop_appnp}\n",
    "\n",
    "# model_args = {\n",
    "#     'hiddenunits': [64],\n",
    "#     'drop_prob': 0.5,\n",
    "#     'propagation': prop_ppnp_pre}\n",
    "\n",
    "# model_args = {\n",
    "#     'adj_matrix': graph.adj_matrix,\n",
    "#     'hiddenunits': [64],\n",
    "#     'drop_prob': 0.5,\n",
    "#     'niter': 10,\n",
    "#     'alpha': alpha\n",
    "# }\n",
    "\n",
    "reg_lambda = 5e-3\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model\n",
    "\n",
    "First we set the remaining settings for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "niter_per_seed = 1\n",
    "save_result = False\n",
    "print_interval = 10\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use 20 different seeds for splitting and 5 iterations (different random initializations) per split, so we train 100 times altogether. This will take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-29 16:04:08: Iteration 1 of 20\n",
      "                     -----------------\n",
      "2020-05-29 16:04:08: PyTorch seed: 117193973\n",
      "2020-05-29 16:40:56: Last epoch: 922, best epoch: 822 (2207.501 sec)\n",
      "2020-05-29 16:40:59: Test accuracy: 79.6%\n",
      "2020-05-29 16:41:00: Iteration 2 of 20\n",
      "                     -----------------\n",
      "2020-05-29 16:41:00: PyTorch seed: 4188038451\n",
      "2020-05-29 17:08:00: Last epoch: 679, best epoch: 307 (1620.420 sec)\n",
      "2020-05-29 17:08:03: Test accuracy: 75.4%\n",
      "2020-05-29 17:08:04: Iteration 3 of 20\n",
      "                     -----------------\n",
      "2020-05-29 17:08:04: PyTorch seed: 1249166017\n",
      "2020-05-29 17:25:29: Last epoch: 547, best epoch: 447 (1044.369 sec)\n",
      "2020-05-29 17:25:31: Test accuracy: 77.5%\n",
      "2020-05-29 17:25:32: Iteration 4 of 20\n",
      "                     -----------------\n",
      "2020-05-29 17:25:32: PyTorch seed: 4024025798\n",
      "2020-05-29 17:59:01: Last epoch: 1066, best epoch: 966 (2009.190 sec)\n",
      "2020-05-29 17:59:04: Test accuracy: 77.1%\n",
      "2020-05-29 17:59:04: Iteration 5 of 20\n",
      "                     -----------------\n",
      "2020-05-29 17:59:04: PyTorch seed: 1789940426\n",
      "2020-05-29 18:19:12: Last epoch: 974, best epoch: 194 (1207.463 sec)\n",
      "2020-05-29 18:19:13: Test accuracy: 79.8%\n",
      "2020-05-29 18:19:13: Iteration 6 of 20\n",
      "                     -----------------\n",
      "2020-05-29 18:19:13: PyTorch seed: 726755453\n",
      "2020-05-29 18:25:59: Last epoch: 887, best epoch: 591 (406.075 sec)\n",
      "2020-05-29 18:26:00: Test accuracy: 79.7%\n",
      "2020-05-29 18:26:00: Iteration 7 of 20\n",
      "                     -----------------\n",
      "2020-05-29 18:26:00: PyTorch seed: 2166110159\n",
      "2020-05-29 18:33:28: Last epoch: 991, best epoch: 485 (447.884 sec)\n",
      "2020-05-29 18:33:29: Test accuracy: 80.7%\n",
      "2020-05-29 18:33:29: Iteration 8 of 20\n",
      "                     -----------------\n",
      "2020-05-29 18:33:29: PyTorch seed: 3299790680\n",
      "2020-05-29 18:38:53: Last epoch: 713, best epoch: 514 (323.474 sec)\n",
      "2020-05-29 18:38:53: Test accuracy: 79.2%\n",
      "2020-05-29 18:38:54: Iteration 9 of 20\n",
      "                     -----------------\n",
      "2020-05-29 18:38:54: PyTorch seed: 1685852260\n",
      "2020-05-29 18:45:03: Last epoch: 813, best epoch: 713 (369.670 sec)\n",
      "2020-05-29 18:45:04: Test accuracy: 81.6%\n",
      "2020-05-29 18:45:04: Iteration 10 of 20\n",
      "                     ------------------\n",
      "2020-05-29 18:45:04: PyTorch seed: 3618528237\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = []\n",
    "niter_tot = niter_per_seed * len(seeds)\n",
    "i_tot = 0\n",
    "for seed in seeds:\n",
    "    idx_split_args['seed'] = seed\n",
    "    for _ in range(niter_per_seed):\n",
    "        i_tot += 1\n",
    "        logging_string = f\"Iteration {i_tot} of {niter_tot}\"\n",
    "        logging.log(22,\n",
    "                logging_string + \"\\n                     \"\n",
    "                + '-' * len(logging_string))\n",
    "        model, result = train_model(\n",
    "            graph_name, PPNP, graph, model_args, learning_rate, reg_lambda,\n",
    "            idx_split_args, stopping_args, test, device, None, print_interval)\n",
    "        results.append({})\n",
    "        results[-1]['stopping_accuracy'] = result['early_stopping']['accuracy']\n",
    "        results[-1]['valtest_accuracy'] = result['valtest']['accuracy']\n",
    "        results[-1]['runtime'] = result['runtime']\n",
    "        results[-1]['runtime_perepoch'] = result['runtime_perepoch']\n",
    "        results[-1]['split_seed'] = seed\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## forward computation time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 701 ms, sys: 74.6 ms, total: 776 ms\n",
      "Wall time: 105 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# from ppnp.preprocessing import normalize_attributes\n",
    "# from ppnp.pytorch.training import get_predictions\n",
    "# from ppnp.pytorch.utils import matrix_to_torch\n",
    "\n",
    "# labels_all = graph.labels\n",
    "# attr_mat_norm_np = normalize_attributes(graph.attr_matrix)\n",
    "# attr_mat_norm = matrix_to_torch(attr_mat_norm_np).to(device)\n",
    "\n",
    "# nfeatures = graph.attr_matrix.shape[1]\n",
    "# nclasses = max(labels_all) + 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_args = {\n",
    "#     'hiddenunits': [64],\n",
    "#     'drop_prob': 0.5,\n",
    "#     'propagation': prop_ppnp_pre}\n",
    "# model = PPNP(nfeatures, nclasses, **model_args).to(device)\n",
    "model.propagation = prop_ppnp_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.6 ms, sys: 128 µs, total: 24.7 ms\n",
      "Wall time: 23.7 ms\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%time res = get_predictions(model, attr_mat_norm, torch.arange(len(labels_all)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_args = {\n",
    "#     'hiddenunits': [64],\n",
    "#     'drop_prob': 0.5,\n",
    "#     'propagation': prop_appnp}\n",
    "# model = PPNP(nfeatures, nclasses, **model_args).to(device)\n",
    "model.propagation = prop_appnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.7 ms, sys: 0 ns, total: 35.7 ms\n",
      "Wall time: 34.9 ms\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%time res = get_predictions(model, attr_mat_norm, torch.arange(len(labels_all)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "To evaluate the data we use Pandas and Seaborn (for bootstrapping)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stopping_accuracy</th>\n",
       "      <th>valtest_accuracy</th>\n",
       "      <th>runtime</th>\n",
       "      <th>runtime_perepoch</th>\n",
       "      <th>split_seed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.795685</td>\n",
       "      <td>2207.500894</td>\n",
       "      <td>2.391659</td>\n",
       "      <td>2144199730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.792</td>\n",
       "      <td>0.753856</td>\n",
       "      <td>1620.420109</td>\n",
       "      <td>2.382971</td>\n",
       "      <td>794209841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.774</td>\n",
       "      <td>0.775265</td>\n",
       "      <td>1044.369177</td>\n",
       "      <td>1.905783</td>\n",
       "      <td>2985733717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.762</td>\n",
       "      <td>0.770928</td>\n",
       "      <td>2009.190199</td>\n",
       "      <td>1.883027</td>\n",
       "      <td>2282690970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.797936</td>\n",
       "      <td>1207.463277</td>\n",
       "      <td>1.238424</td>\n",
       "      <td>1901557222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.796783</td>\n",
       "      <td>406.074782</td>\n",
       "      <td>0.457291</td>\n",
       "      <td>2009332812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.832</td>\n",
       "      <td>0.806774</td>\n",
       "      <td>447.883710</td>\n",
       "      <td>0.451496</td>\n",
       "      <td>2266730407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.792282</td>\n",
       "      <td>323.474397</td>\n",
       "      <td>0.453045</td>\n",
       "      <td>635625077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.840</td>\n",
       "      <td>0.816325</td>\n",
       "      <td>369.669514</td>\n",
       "      <td>0.454139</td>\n",
       "      <td>3538425002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.816</td>\n",
       "      <td>0.817204</td>\n",
       "      <td>436.566737</td>\n",
       "      <td>0.455231</td>\n",
       "      <td>960893189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.756</td>\n",
       "      <td>0.798650</td>\n",
       "      <td>465.850094</td>\n",
       "      <td>0.453162</td>\n",
       "      <td>497096336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.795191</td>\n",
       "      <td>413.252132</td>\n",
       "      <td>0.396595</td>\n",
       "      <td>3940842554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.774</td>\n",
       "      <td>0.772355</td>\n",
       "      <td>265.170826</td>\n",
       "      <td>0.300647</td>\n",
       "      <td>3594628340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.780150</td>\n",
       "      <td>266.766402</td>\n",
       "      <td>0.292828</td>\n",
       "      <td>948012117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.764</td>\n",
       "      <td>0.762584</td>\n",
       "      <td>165.360444</td>\n",
       "      <td>0.290616</td>\n",
       "      <td>3305901371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.778</td>\n",
       "      <td>0.790580</td>\n",
       "      <td>218.112316</td>\n",
       "      <td>0.288890</td>\n",
       "      <td>3644534211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.810</td>\n",
       "      <td>0.785036</td>\n",
       "      <td>268.385687</td>\n",
       "      <td>0.297875</td>\n",
       "      <td>2297033685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.792502</td>\n",
       "      <td>401.739445</td>\n",
       "      <td>0.296925</td>\n",
       "      <td>4092258879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.756</td>\n",
       "      <td>0.762530</td>\n",
       "      <td>642.092994</td>\n",
       "      <td>0.712645</td>\n",
       "      <td>2590091101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.716</td>\n",
       "      <td>0.749629</td>\n",
       "      <td>941.900437</td>\n",
       "      <td>1.228032</td>\n",
       "      <td>1694925034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    stopping_accuracy  valtest_accuracy      runtime  runtime_perepoch  \\\n",
       "0               0.808          0.795685  2207.500894          2.391659   \n",
       "1               0.792          0.753856  1620.420109          2.382971   \n",
       "2               0.774          0.775265  1044.369177          1.905783   \n",
       "3               0.762          0.770928  2009.190199          1.883027   \n",
       "4               0.804          0.797936  1207.463277          1.238424   \n",
       "5               0.804          0.796783   406.074782          0.457291   \n",
       "6               0.832          0.806774   447.883710          0.451496   \n",
       "7               0.798          0.792282   323.474397          0.453045   \n",
       "8               0.840          0.816325   369.669514          0.454139   \n",
       "9               0.816          0.817204   436.566737          0.455231   \n",
       "10              0.756          0.798650   465.850094          0.453162   \n",
       "11              0.798          0.795191   413.252132          0.396595   \n",
       "12              0.774          0.772355   265.170826          0.300647   \n",
       "13              0.806          0.780150   266.766402          0.292828   \n",
       "14              0.764          0.762584   165.360444          0.290616   \n",
       "15              0.778          0.790580   218.112316          0.288890   \n",
       "16              0.810          0.785036   268.385687          0.297875   \n",
       "17              0.802          0.792502   401.739445          0.296925   \n",
       "18              0.756          0.762530   642.092994          0.712645   \n",
       "19              0.716          0.749629   941.900437          1.228032   \n",
       "\n",
       "    split_seed  \n",
       "0   2144199730  \n",
       "1    794209841  \n",
       "2   2985733717  \n",
       "3   2282690970  \n",
       "4   1901557222  \n",
       "5   2009332812  \n",
       "6   2266730407  \n",
       "7    635625077  \n",
       "8   3538425002  \n",
       "9    960893189  \n",
       "10   497096336  \n",
       "11  3940842554  \n",
       "12  3594628340  \n",
       "13   948012117  \n",
       "14  3305901371  \n",
       "15  3644534211  \n",
       "16  2297033685  \n",
       "17  4092258879  \n",
       "18  2590091101  \n",
       "19  1694925034  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.DataFrame(results)\n",
    "result_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard deviation doesn't really say much about the uncertainty of our results and the standard error of the mean (SEM) assumes a normal distribution. So the best way to get a valid estimate for our results' uncertainty is via bootstrapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_uncertainty(values: np.ndarray, n_boot: int = 1000, ci: int = 95) -> dict:\n",
    "    stats = {}\n",
    "    stats['mean'] = values.mean()\n",
    "    boots_series = sns.algorithms.bootstrap(values, func=np.mean, n_boot=n_boot)\n",
    "    stats['CI'] = sns.utils.ci(boots_series, ci)\n",
    "    stats['uncertainty'] = np.max(np.abs(stats['CI'] - stats['mean']))\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopping_acc = calc_uncertainty(result_df['stopping_accuracy'])\n",
    "valtest_acc = calc_uncertainty(result_df['valtest_accuracy'])\n",
    "runtime = calc_uncertainty(result_df['runtime'])\n",
    "runtime_perepoch = calc_uncertainty(result_df['runtime_perepoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APPNP\n",
      "Early stopping: Accuracy: 78.95 ± 1.24%\n",
      "Test: Accuracy: 78.56 ± 0.81%\n",
      "Runtime: 706.062 ± 268.695 sec, per epoch: 831.56 ± 324.49ms\n"
     ]
    }
   ],
   "source": [
    "print(\"APPNP\\n\"\n",
    "      \"Early stopping: Accuracy: {:.2f} ± {:.2f}%\\n\"\n",
    "      \"{}: Accuracy: {:.2f} ± {:.2f}%\\n\"\n",
    "      \"Runtime: {:.3f} ± {:.3f} sec, per epoch: {:.2f} ± {:.2f}ms\"\n",
    "      .format(\n",
    "          stopping_acc['mean'] * 100,\n",
    "          stopping_acc['uncertainty'] * 100,\n",
    "          'Test' if test else 'Validation',\n",
    "          valtest_acc['mean'] * 100,\n",
    "          valtest_acc['uncertainty'] * 100,\n",
    "          runtime['mean'],\n",
    "          runtime['uncertainty'],\n",
    "          runtime_perepoch['mean'] * 1e3,\n",
    "          runtime_perepoch['uncertainty'] * 1e3,\n",
    "      ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "original:\n",
    "APPNP\n",
    "Early stopping: Accuracy: 80.40 ± 0.00%\n",
    "Test: Accuracy: 82.90 ± 0.00%\n",
    "Runtime: 62.598 ± 0.000 sec, per epoch: 41.29 ± 0.00ms\n",
    "\n",
    "re-run:\n",
    "APPNP\n",
    "Early stopping: Accuracy: 81.23 ± 0.42%\n",
    "Test: Accuracy: 83.60 ± 0.32%\n",
    "Runtime: 71.608 ± 2.747 sec, per epoch: 42.81 ± 0.37ms\n",
    "\n",
    "ppnp_d:\n",
    "A is symmatric, niter=6\n",
    "APPNP\n",
    "Early stopping: Accuracy: 77.94 ± 0.59%\n",
    "Test: Accuracy: 79.70 ± 0.45%\n",
    "Runtime: 3.912 ± 0.358 sec, per epoch: 20.55 ± 0.15ms\n",
    "\n",
    "ppnp_d:\n",
    "A is symmatric, niter=10\n",
    "APPNP\n",
    "Early stopping: Accuracy: 78.37 ± 0.62%\n",
    "Test: Accuracy: 80.38 ± 0.50%\n",
    "Runtime: 4.173 ± 0.235 sec, per epoch: 21.68 ± 0.12ms\n",
    "\n",
    "ppnp_pre:\n",
    "pre-compute PPR matrix (iterative), niter=10\n",
    "APPNP\n",
    "Early stopping: Accuracy: 81.34 ± 0.41%\n",
    "Test: Accuracy: 83.74 ± 0.30%\n",
    "Runtime: 32.504 ± 1.218 sec, per epoch: 19.06 ± 0.11ms\n",
    "\n",
    "ppnp_pre:\n",
    "pre-compute PPR matrix (iterative), niter=20\n",
    "APPNP\n",
    "Early stopping: Accuracy: 81.34 ± 0.39%\n",
    "Test: Accuracy: 83.74 ± 0.33%\n",
    "Runtime: 32.048 ± 1.240 sec, per epoch: 18.94 ± 0.10ms\n",
    "\n",
    "PPRGCN:\n",
    "APPNP\n",
    "Early stopping: Accuracy: 80.95 ± 0.46%\n",
    "Test: Accuracy: 83.38 ± 0.32%\n",
    "Runtime: 25.545 ± 1.067 sec, per epoch: 18.63 ± 0.07ms\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
