{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import logging\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "from ppnp.pytorch import PPNP, PPRGCN\n",
    "from ppnp.pytorch.training import train_model\n",
    "from ppnp.pytorch.earlystopping import stopping_args\n",
    "from ppnp.pytorch.propagation import PPRExact, PPRPowerIteration, DiffusionIteration, PrePPRIteration\n",
    "from ppnp.data.io import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "        format='%(asctime)s: %(message)s',\n",
    "        datefmt='%Y-%m-%d %H:%M:%S',\n",
    "        level=logging.INFO + 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch variant\n",
    "This is not the official code that should be used to reproduce the results from the paper (see `reproduce_results.ipynb` for this), but an adaptation of that code to PyTorch for better accessibility. This notebook reproduces the accuracy of the TensorFlow implementation, but has a longer computation time and varies in some details due to the change to PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Undirected, unweighted and connected SparseGraph with 88648 edges (no self-loops). Data: adj_matrix (19717x19717), attr_matrix (19717x500), labels (19717)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_name = 'pubmed' # cora_ml, citeseer, ms_academic, pubmed\n",
    "graph = load_dataset(graph_name)\n",
    "graph.standardize(select_lcc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "import sys\n",
    "sys.path.append('../gnn-untitled/')\n",
    "\n",
    "data_dir = Path('../gnn-untitled/pprie/data')\n",
    "graph_name = 'cora_ml_2c.SG'\n",
    "path_to_file = data_dir / graph_name\n",
    "\n",
    "with open(path_to_file, 'rb') as f:\n",
    "    new_graph = pickle.load(f)\n",
    "new_graph    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up data splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all we need to decide whether to use the test or validation set. Be mindful that we can only look at the test set exactly _once_ and then can't change any hyperparameters oder model details, no matter what. Everything else would cause overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the seeds for the dataset splits used in the paper for test/validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_seeds = [\n",
    "        2144199730,  794209841, 2985733717, 2282690970, 1901557222,\n",
    "        2009332812, 2266730407,  635625077, 3538425002,  960893189,\n",
    "        497096336, 3940842554, 3594628340,  948012117, 3305901371,\n",
    "        3644534211, 2297033685, 4092258879, 2590091101, 1694925034]\n",
    "# test_seeds = [2144199730, ]\n",
    "\n",
    "val_seeds = [\n",
    "        2413340114, 3258769933, 1789234713, 2222151463, 2813247115,\n",
    "        1920426428, 4272044734, 2092442742, 841404887, 2188879532,\n",
    "        646784207, 1633698412, 2256863076,  374355442,  289680769,\n",
    "        4281139389, 4263036964,  900418539,  119332950, 1628837138]\n",
    "\n",
    "if test:\n",
    "    seeds = test_seeds\n",
    "else:\n",
    "    seeds = val_seeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can choose the remaining settings for the training/early stopping/validation(test) split. These are the ones chosen in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if graph_name == 'microsoft_academic':\n",
    "    nknown = 5000\n",
    "else:\n",
    "    nknown = 1500\n",
    "    \n",
    "idx_split_args = {'ntrain_per_class': 20, 'nstopping': 500, 'nknown': nknown}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up propagation\n",
    "\n",
    "Next we need to set up the proper pmropagation scheme. In the paper we've introduced the exact PPR propagation used in PPNP and the PPR power iteration propagation used in APPNP.\n",
    "\n",
    "We use the hyperparameters from the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41.3 ms, sys: 9.62 ms, total: 50.9 ms\n",
      "Wall time: 16.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if graph_name == 'microsoft_academic':\n",
    "    alpha = 0.2\n",
    "else:\n",
    "    alpha = 0.1\n",
    "\n",
    "# prop_ppnp = PPRExact(graph.adj_matrix, alpha=alpha)\n",
    "prop_appnp = PPRPowerIteration(graph.adj_matrix, alpha=alpha, niter=40)\n",
    "# prop_ppnp_d = DiffusionIteration(graph.adj_matrix, niter=10)\n",
    "# prop_ppnp_pre = PrePPRIteration(graph.adj_matrix, alpha=alpha, niter=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose model hyperparameters\n",
    "\n",
    "Now we choose the hyperparameters. These are the ones used in the paper for all datasets.\n",
    "\n",
    "Note that we choose the propagation for APPNP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = {\n",
    "    'hiddenunits': [64],\n",
    "    'drop_prob': 0.5,\n",
    "    'propagation': prop_appnp}\n",
    "\n",
    "# model_args = {\n",
    "#     'hiddenunits': [64],\n",
    "#     'drop_prob': 0.5,\n",
    "#     'propagation': prop_ppnp_pre}\n",
    "\n",
    "# model_args = {\n",
    "#     'adj_matrix': graph.adj_matrix,\n",
    "#     'hiddenunits': [64],\n",
    "#     'drop_prob': 0.5,\n",
    "#     'niter': 10,\n",
    "#     'alpha': alpha\n",
    "# }\n",
    "\n",
    "reg_lambda = 5e-3\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model\n",
    "\n",
    "First we set the remaining settings for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "niter_per_seed = 1\n",
    "save_result = False\n",
    "print_interval = 10\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use 20 different seeds for splitting and 5 iterations (different random initializations) per split, so we train 100 times altogether. This will take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-29 16:04:35: Iteration 1 of 20\n",
      "                     -----------------\n",
      "2020-05-29 16:04:35: PyTorch seed: 448795951\n",
      "2020-05-29 17:10:01: Last epoch: 908, best epoch: 492 (3926.200 sec)\n",
      "2020-05-29 17:10:05: Test accuracy: 79.7%\n",
      "2020-05-29 17:10:06: Iteration 2 of 20\n",
      "                     -----------------\n",
      "2020-05-29 17:10:07: PyTorch seed: 2133187232\n",
      "2020-05-29 18:13:11: Last epoch: 1172, best epoch: 271 (3784.622 sec)\n",
      "2020-05-29 18:13:14: Test accuracy: 73.8%\n",
      "2020-05-29 18:13:15: Iteration 3 of 20\n",
      "                     -----------------\n",
      "2020-05-29 18:13:15: PyTorch seed: 3678683933\n",
      "2020-05-29 18:25:29: Last epoch: 696, best epoch: 351 (733.617 sec)\n",
      "2020-05-29 18:25:30: Test accuracy: 78.1%\n",
      "2020-05-29 18:25:30: Iteration 4 of 20\n",
      "                     -----------------\n",
      "2020-05-29 18:25:30: PyTorch seed: 634236767\n",
      "2020-05-29 18:34:16: Last epoch: 645, best epoch: 544 (525.942 sec)\n",
      "2020-05-29 18:34:17: Test accuracy: 78.2%\n",
      "2020-05-29 18:34:18: Iteration 5 of 20\n",
      "                     -----------------\n",
      "2020-05-29 18:34:18: PyTorch seed: 1688438938\n",
      "2020-05-29 18:44:25: Last epoch: 743, best epoch: 539 (607.452 sec)\n",
      "2020-05-29 18:44:26: Test accuracy: 79.7%\n",
      "2020-05-29 18:44:27: Iteration 6 of 20\n",
      "                     -----------------\n",
      "2020-05-29 18:44:27: PyTorch seed: 2230965675\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = []\n",
    "niter_tot = niter_per_seed * len(seeds)\n",
    "i_tot = 0\n",
    "for seed in seeds:\n",
    "    idx_split_args['seed'] = seed\n",
    "    for _ in range(niter_per_seed):\n",
    "        i_tot += 1\n",
    "        logging_string = f\"Iteration {i_tot} of {niter_tot}\"\n",
    "        logging.log(22,\n",
    "                logging_string + \"\\n                     \"\n",
    "                + '-' * len(logging_string))\n",
    "        model, result = train_model(\n",
    "            graph_name, PPNP, graph, model_args, learning_rate, reg_lambda,\n",
    "            idx_split_args, stopping_args, test, device, None, print_interval)\n",
    "        results.append({})\n",
    "        results[-1]['stopping_accuracy'] = result['early_stopping']['accuracy']\n",
    "        results[-1]['valtest_accuracy'] = result['valtest']['accuracy']\n",
    "        results[-1]['runtime'] = result['runtime']\n",
    "        results[-1]['runtime_perepoch'] = result['runtime_perepoch']\n",
    "        results[-1]['split_seed'] = seed\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## forward computation time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 701 ms, sys: 74.6 ms, total: 776 ms\n",
      "Wall time: 105 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# from ppnp.preprocessing import normalize_attributes\n",
    "# from ppnp.pytorch.training import get_predictions\n",
    "# from ppnp.pytorch.utils import matrix_to_torch\n",
    "\n",
    "# labels_all = graph.labels\n",
    "# attr_mat_norm_np = normalize_attributes(graph.attr_matrix)\n",
    "# attr_mat_norm = matrix_to_torch(attr_mat_norm_np).to(device)\n",
    "\n",
    "# nfeatures = graph.attr_matrix.shape[1]\n",
    "# nclasses = max(labels_all) + 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_args = {\n",
    "#     'hiddenunits': [64],\n",
    "#     'drop_prob': 0.5,\n",
    "#     'propagation': prop_ppnp_pre}\n",
    "# model = PPNP(nfeatures, nclasses, **model_args).to(device)\n",
    "model.propagation = prop_ppnp_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.6 ms, sys: 128 µs, total: 24.7 ms\n",
      "Wall time: 23.7 ms\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%time res = get_predictions(model, attr_mat_norm, torch.arange(len(labels_all)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_args = {\n",
    "#     'hiddenunits': [64],\n",
    "#     'drop_prob': 0.5,\n",
    "#     'propagation': prop_appnp}\n",
    "# model = PPNP(nfeatures, nclasses, **model_args).to(device)\n",
    "model.propagation = prop_appnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.7 ms, sys: 0 ns, total: 35.7 ms\n",
      "Wall time: 34.9 ms\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%time res = get_predictions(model, attr_mat_norm, torch.arange(len(labels_all)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "To evaluate the data we use Pandas and Seaborn (for bootstrapping)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stopping_accuracy</th>\n",
       "      <th>valtest_accuracy</th>\n",
       "      <th>runtime</th>\n",
       "      <th>runtime_perepoch</th>\n",
       "      <th>split_seed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.792</td>\n",
       "      <td>0.796783</td>\n",
       "      <td>3926.200240</td>\n",
       "      <td>4.319252</td>\n",
       "      <td>2144199730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.756</td>\n",
       "      <td>0.737608</td>\n",
       "      <td>3784.621793</td>\n",
       "      <td>3.226447</td>\n",
       "      <td>794209841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.774</td>\n",
       "      <td>0.780864</td>\n",
       "      <td>733.617392</td>\n",
       "      <td>1.052536</td>\n",
       "      <td>2985733717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.764</td>\n",
       "      <td>0.781852</td>\n",
       "      <td>525.942293</td>\n",
       "      <td>0.814152</td>\n",
       "      <td>2282690970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.797222</td>\n",
       "      <td>607.451985</td>\n",
       "      <td>0.816468</td>\n",
       "      <td>1901557222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.812</td>\n",
       "      <td>0.804798</td>\n",
       "      <td>791.572221</td>\n",
       "      <td>0.813538</td>\n",
       "      <td>2009332812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.816</td>\n",
       "      <td>0.799144</td>\n",
       "      <td>860.220753</td>\n",
       "      <td>0.637201</td>\n",
       "      <td>2266730407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.784</td>\n",
       "      <td>0.789373</td>\n",
       "      <td>433.341316</td>\n",
       "      <td>0.522098</td>\n",
       "      <td>635625077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.828</td>\n",
       "      <td>0.815173</td>\n",
       "      <td>680.498271</td>\n",
       "      <td>0.521455</td>\n",
       "      <td>3538425002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.812</td>\n",
       "      <td>0.812702</td>\n",
       "      <td>2766.962711</td>\n",
       "      <td>1.562373</td>\n",
       "      <td>960893189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.752</td>\n",
       "      <td>0.807542</td>\n",
       "      <td>1558.997954</td>\n",
       "      <td>1.988518</td>\n",
       "      <td>497096336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.810</td>\n",
       "      <td>0.802492</td>\n",
       "      <td>810.282721</td>\n",
       "      <td>0.757982</td>\n",
       "      <td>3940842554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.776</td>\n",
       "      <td>0.779272</td>\n",
       "      <td>650.163697</td>\n",
       "      <td>0.798727</td>\n",
       "      <td>3594628340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.785585</td>\n",
       "      <td>953.705174</td>\n",
       "      <td>1.035511</td>\n",
       "      <td>948012117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.766</td>\n",
       "      <td>0.751715</td>\n",
       "      <td>693.045126</td>\n",
       "      <td>0.939086</td>\n",
       "      <td>3305901371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.774</td>\n",
       "      <td>0.772136</td>\n",
       "      <td>254.736762</td>\n",
       "      <td>0.354787</td>\n",
       "      <td>3644534211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.794</td>\n",
       "      <td>0.777955</td>\n",
       "      <td>187.564832</td>\n",
       "      <td>0.161694</td>\n",
       "      <td>2297033685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.812</td>\n",
       "      <td>0.801065</td>\n",
       "      <td>204.257562</td>\n",
       "      <td>0.166469</td>\n",
       "      <td>4092258879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.746</td>\n",
       "      <td>0.760828</td>\n",
       "      <td>127.972774</td>\n",
       "      <td>0.159766</td>\n",
       "      <td>2590091101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.710</td>\n",
       "      <td>0.745458</td>\n",
       "      <td>150.378600</td>\n",
       "      <td>0.160661</td>\n",
       "      <td>1694925034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    stopping_accuracy  valtest_accuracy      runtime  runtime_perepoch  \\\n",
       "0               0.792          0.796783  3926.200240          4.319252   \n",
       "1               0.756          0.737608  3784.621793          3.226447   \n",
       "2               0.774          0.780864   733.617392          1.052536   \n",
       "3               0.764          0.781852   525.942293          0.814152   \n",
       "4               0.800          0.797222   607.451985          0.816468   \n",
       "5               0.812          0.804798   791.572221          0.813538   \n",
       "6               0.816          0.799144   860.220753          0.637201   \n",
       "7               0.784          0.789373   433.341316          0.522098   \n",
       "8               0.828          0.815173   680.498271          0.521455   \n",
       "9               0.812          0.812702  2766.962711          1.562373   \n",
       "10              0.752          0.807542  1558.997954          1.988518   \n",
       "11              0.810          0.802492   810.282721          0.757982   \n",
       "12              0.776          0.779272   650.163697          0.798727   \n",
       "13              0.806          0.785585   953.705174          1.035511   \n",
       "14              0.766          0.751715   693.045126          0.939086   \n",
       "15              0.774          0.772136   254.736762          0.354787   \n",
       "16              0.794          0.777955   187.564832          0.161694   \n",
       "17              0.812          0.801065   204.257562          0.166469   \n",
       "18              0.746          0.760828   127.972774          0.159766   \n",
       "19              0.710          0.745458   150.378600          0.160661   \n",
       "\n",
       "    split_seed  \n",
       "0   2144199730  \n",
       "1    794209841  \n",
       "2   2985733717  \n",
       "3   2282690970  \n",
       "4   1901557222  \n",
       "5   2009332812  \n",
       "6   2266730407  \n",
       "7    635625077  \n",
       "8   3538425002  \n",
       "9    960893189  \n",
       "10   497096336  \n",
       "11  3940842554  \n",
       "12  3594628340  \n",
       "13   948012117  \n",
       "14  3305901371  \n",
       "15  3644534211  \n",
       "16  2297033685  \n",
       "17  4092258879  \n",
       "18  2590091101  \n",
       "19  1694925034  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.DataFrame(results)\n",
    "result_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard deviation doesn't really say much about the uncertainty of our results and the standard error of the mean (SEM) assumes a normal distribution. So the best way to get a valid estimate for our results' uncertainty is via bootstrapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_uncertainty(values: np.ndarray, n_boot: int = 1000, ci: int = 95) -> dict:\n",
    "    stats = {}\n",
    "    stats['mean'] = values.mean()\n",
    "    boots_series = sns.algorithms.bootstrap(values, func=np.mean, n_boot=n_boot)\n",
    "    stats['CI'] = sns.utils.ci(boots_series, ci)\n",
    "    stats['uncertainty'] = np.max(np.abs(stats['CI'] - stats['mean']))\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopping_acc = calc_uncertainty(result_df['stopping_accuracy'])\n",
    "valtest_acc = calc_uncertainty(result_df['valtest_accuracy'])\n",
    "runtime = calc_uncertainty(result_df['runtime'])\n",
    "runtime_perepoch = calc_uncertainty(result_df['runtime_perepoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APPNP\n",
      "Early stopping: Accuracy: 78.42 ± 1.30%\n",
      "Test: Accuracy: 78.50 ± 1.00%\n",
      "Runtime: 1035.077 ± 548.630 sec, per epoch: 1040.44 ± 507.52ms\n"
     ]
    }
   ],
   "source": [
    "print(\"APPNP\\n\"\n",
    "      \"Early stopping: Accuracy: {:.2f} ± {:.2f}%\\n\"\n",
    "      \"{}: Accuracy: {:.2f} ± {:.2f}%\\n\"\n",
    "      \"Runtime: {:.3f} ± {:.3f} sec, per epoch: {:.2f} ± {:.2f}ms\"\n",
    "      .format(\n",
    "          stopping_acc['mean'] * 100,\n",
    "          stopping_acc['uncertainty'] * 100,\n",
    "          'Test' if test else 'Validation',\n",
    "          valtest_acc['mean'] * 100,\n",
    "          valtest_acc['uncertainty'] * 100,\n",
    "          runtime['mean'],\n",
    "          runtime['uncertainty'],\n",
    "          runtime_perepoch['mean'] * 1e3,\n",
    "          runtime_perepoch['uncertainty'] * 1e3,\n",
    "      ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "original:\n",
    "APPNP\n",
    "Early stopping: Accuracy: 80.40 ± 0.00%\n",
    "Test: Accuracy: 82.90 ± 0.00%\n",
    "Runtime: 62.598 ± 0.000 sec, per epoch: 41.29 ± 0.00ms\n",
    "\n",
    "re-run:\n",
    "APPNP\n",
    "Early stopping: Accuracy: 81.23 ± 0.42%\n",
    "Test: Accuracy: 83.60 ± 0.32%\n",
    "Runtime: 71.608 ± 2.747 sec, per epoch: 42.81 ± 0.37ms\n",
    "\n",
    "ppnp_d:\n",
    "A is symmatric, niter=6\n",
    "APPNP\n",
    "Early stopping: Accuracy: 77.94 ± 0.59%\n",
    "Test: Accuracy: 79.70 ± 0.45%\n",
    "Runtime: 3.912 ± 0.358 sec, per epoch: 20.55 ± 0.15ms\n",
    "\n",
    "ppnp_d:\n",
    "A is symmatric, niter=10\n",
    "APPNP\n",
    "Early stopping: Accuracy: 78.37 ± 0.62%\n",
    "Test: Accuracy: 80.38 ± 0.50%\n",
    "Runtime: 4.173 ± 0.235 sec, per epoch: 21.68 ± 0.12ms\n",
    "\n",
    "ppnp_pre:\n",
    "pre-compute PPR matrix (iterative), niter=10\n",
    "APPNP\n",
    "Early stopping: Accuracy: 81.34 ± 0.41%\n",
    "Test: Accuracy: 83.74 ± 0.30%\n",
    "Runtime: 32.504 ± 1.218 sec, per epoch: 19.06 ± 0.11ms\n",
    "\n",
    "ppnp_pre:\n",
    "pre-compute PPR matrix (iterative), niter=20\n",
    "APPNP\n",
    "Early stopping: Accuracy: 81.34 ± 0.39%\n",
    "Test: Accuracy: 83.74 ± 0.33%\n",
    "Runtime: 32.048 ± 1.240 sec, per epoch: 18.94 ± 0.10ms\n",
    "\n",
    "PPRGCN:\n",
    "APPNP\n",
    "Early stopping: Accuracy: 80.95 ± 0.46%\n",
    "Test: Accuracy: 83.38 ± 0.32%\n",
    "Runtime: 25.545 ± 1.067 sec, per epoch: 18.63 ± 0.07ms\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
